{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkPm6aRMMken"
      },
      "source": [
        "# How to make tensors on gpu instead of cpu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXRmZaneH7Z3"
      },
      "source": [
        "## This notebook is made on google colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8JEWd0DxH8s3"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWuMl_TYIIrx",
        "outputId": "17249799-3d9a-45e0-a2ce-320d1adc78b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available\n",
            "Using GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU thank you.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8XPJzJIpIdVa"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnbWTXyPL7p3",
        "outputId": "33cac043-9f7a-4cfa-803d-9dd6aa1f0f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3928, 0.9480, 0.8579],\n",
              "        [0.8530, 0.6310, 0.6073]], device='cuda:0')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a new tensor on gpu\n",
        "a = torch.rand((2,3), device=device)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT54ML9xNMKW"
      },
      "source": [
        "How to move a existing tensor to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7CnCioKMiRH",
        "outputId": "3ee69fc9-92e8-46e7-a22a-c893f4a13a8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6825, 0.1868, 0.2238],\n",
              "        [0.8721, 0.1910, 0.5492]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# moving an existing tensor on gpu\n",
        "b = torch.rand(2,3)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC4VS50kNEBs",
        "outputId": "ca21965d-2cd8-400f-99ee-39ccdcc28bed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6825, 0.1868, 0.2238],\n",
              "        [0.8721, 0.1910, 0.5492]], device='cuda:0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzBBcBzVNKAE",
        "outputId": "902faf12-d3ef-4cd3-fbce-04d6696e94be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5.6825, 5.1868, 5.2238],\n",
              "        [5.8721, 5.1910, 5.5492]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b + 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF_SdV5UN1MW"
      },
      "source": [
        "Let's see we need gpu when it also works on gpu by measuring time of calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63r2ae0gNdVi",
        "outputId": "370e38f4-9035-4d8e-d0dc-652ef5cca4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time on CPU: 15.5911 seconds\n",
            "Time on GPU: 0.1064 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# define the size of the matrices\n",
        "size =  10000 # large size so we can see a visible difference\n",
        "\n",
        "# Create random matrices on CPU\n",
        "mat_cpu1 = torch.rand(size, size)\n",
        "mat_cpu2 = torch.rand(size, size)\n",
        "\n",
        "# Measure time on CPU\n",
        "start_time = time.time()\n",
        "result_cpu = torch.matmul(mat_cpu1, mat_cpu2)\n",
        "end_time = time.time()\n",
        "cpu_time = end_time - start_time\n",
        "\n",
        "print(f\"Time on CPU: {cpu_time:.4f} seconds\")\n",
        "\n",
        "# Move matrices to gpu\n",
        "mat_gpu1 = mat_cpu1.to('cuda')\n",
        "mat_gpu2 = mat_cpu2.to('cuda')\n",
        "\n",
        "# Measure time on GPU\n",
        "start_time = time.time()\n",
        "result_gpu = torch.matmul(mat_gpu1, mat_gpu2)\n",
        "end_time = time.time()\n",
        "gpu_time = end_time - start_time\n",
        "\n",
        "print(f\"Time on GPU: {gpu_time:.4f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
