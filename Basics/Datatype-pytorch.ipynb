{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15ae582",
   "metadata": {},
   "source": [
    "# Datatypes in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29e9cbf",
   "metadata": {},
   "source": [
    "## Floating point types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5f71e",
   "metadata": {},
   "source": [
    "-   torch.float16 / torch.half : 16-bit floating point number(half precision)\n",
    "-   torch.bfloat16 : Brain floating point 16-bit floating point number(wider dynamic range than float16)\n",
    "-   torch.float32 / torch.float : 32-bit floating point number(single precision)(default for many operations)\n",
    "-   torch.float64 / torch.double : 64-bit floating point number(double precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d2a751",
   "metadata": {},
   "source": [
    "## Complex Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec2b0c",
   "metadata": {},
   "source": [
    "-   torch.complex64: 64-bit complex type(real and imaginary parts are 32-bits float), compatible with np.complex64.\n",
    "-   torch.complex128: 128-bit complex type(real and imaginary parts are 64-bits float), compatible with np.complex128."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67848b",
   "metadata": {},
   "source": [
    "## Integer Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743727",
   "metadata": {},
   "source": [
    "-   torch.int8\n",
    "-   torch.uint8 : 8-bits unsigned integer\n",
    "-   torch.int16 / torch.short\n",
    "-   torch.int32 / torch.int\n",
    "-   torch.int64 / torch.long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f688d",
   "metadata": {},
   "source": [
    "## Boolean Data Type\n",
    "-   torch.bool : True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e73007",
   "metadata": {},
   "source": [
    "## Quantized Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05fc446",
   "metadata": {},
   "source": [
    "-   torch.qint8 : Quantized 8-bit signed integer type.\n",
    "-   torch.quint8 : Quantized 8-bit unsigned integer type.\n",
    "-   torch.qint32 : Quantized 32-bit signed integer type(used for specific operations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1296a",
   "metadata": {},
   "source": [
    "## Additional Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301a0f2",
   "metadata": {},
   "source": [
    "-   Aliases: Many of these dtypes have short names (aliases). For example, torch.float32 is also accessible as torch.float and torch.int64 as torch.long.\n",
    "\n",
    "-   Default Behavior: When you create a tensor without specifying its dtype, PyTorch typically defaults to torch.float32 (for floating point numbers) or torch.int64 (for indices), depending on the context.\n",
    "\n",
    "-   Usage: Choosing the right data type is crucial. While lower precision types (like float16) can speed up computations and reduce memory usage, they may lead to numerical instability or reduced accuracy in some scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90578dd",
   "metadata": {},
   "source": [
    "### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677e80d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n",
      "torch.quint8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# A float tensor with default 32-bit precision\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(x.dtype)  # torch.float32\n",
    "\n",
    "# Creating a tensor with int64 type (alias: torch.long)\n",
    "y = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
    "print(y.dtype)  # torch.int64\n",
    "\n",
    "# Creating a tensor with a quantized type (illustrative purpose)\n",
    "# Note: Quantized tensors are generally created via conversion functions.\n",
    "q_per_tensor = torch.quantize_per_tensor(torch.tensor([1.0, 2.0, 3.0]), scale=0.1, zero_point=10, dtype=torch.quint8)\n",
    "print(q_per_tensor.dtype)  # torch.quint8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
